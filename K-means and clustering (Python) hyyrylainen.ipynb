{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means\n",
    "\n",
    "## Data\n",
    "\n",
    "Use the [World Value Survey](http://www.worldvaluessurvey.org/WVSDocumentationWV6.jsp) datafiles and corresponding questionaire and codebook files to understand what is in the data.\n",
    "\n",
    "## Overarching research question\n",
    "\n",
    "What kind of responder groups can emerge from survey responders and do they correspond to nationalities?\n",
    "* Choose some relevant measurements\n",
    "* Run analysis\n",
    "* Interprent\n",
    "\n",
    "## Method\n",
    "\n",
    "There are many tools used for this, we apply [SciKit learn](https://scikit-learn.org/0.16/modules/clustering.html#clustering).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sklearn.cluster\n",
    "import sklearn\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, the question I am interested in answering is what kind of clusters can be found based on from where the people get information on \"What is going on in this country and the world\". In other words, are there any differences in the world in how often people use different media. The variables I chose were:\n",
    "\n",
    "* Daily newspaper (V217)\n",
    "* Printed magazines (V218)\n",
    "* TV news (V219)\n",
    "* Radio news (V220)\n",
    "* Internet (V223)\n",
    "* Talking with friends or collegues (V224)\n",
    "\n",
    "The variables that I dropped from this group were Mobile phone (V211) and email (V222). The was because I am not sure what iit means that you get your information through mobile phone and email seems to be quite synonymous with the internet. The scale that these variables had was based on the question of \"please indicate whether you use it [the source] to obtain information [1:] daily, [2:] weekly, [3:] monthly, [4:] less than monthly and [5:] never\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89565\n",
      "83976\n",
      "83976\n",
      "[['3', '4', '2', '2', '2', '4'], ['2', '3', '4', '3', '3', '3'], ['3', '4', '2', '2', '1', '1'], ['2', '3', '1', '2', '3', '3'], ['3', '4', '2', '2', '2', '3'], ['3', '4', '2', '2', '4', '3'], ['3', '4', '2', '2', '2', '3'], ['1', '3', '1', '2', '4', '4'], ['2', '3', '4', '2', '4', '3'], ['1', '2', '3', '4', '3', '3']]\n"
     ]
    }
   ],
   "source": [
    "## create new data matrix for k-means analysis\n",
    "\n",
    "selected_keys = ['V217', 'V218', 'V219', 'V220', 'V223', 'V224']\n",
    "\n",
    "number_of_lines = 0\n",
    "\n",
    "data = []\n",
    "country = []\n",
    "\n",
    "for line in csv.DictReader( open('data/wvs.csv', encoding='utf8') ):\n",
    "    number_of_lines += 1\n",
    "    dd = []\n",
    "    add_line_to_data = True\n",
    "    \n",
    "    for key in selected_keys:\n",
    "        if int(line[key]) <= 0:\n",
    "            add_line_to_data = False\n",
    "        dd.append( line[key] )\n",
    "        \n",
    "    if add_line_to_data == True:\n",
    "        country.append(line['COW'])\n",
    "        data.append(dd)\n",
    "\n",
    "print(number_of_lines)\n",
    "print( len( data ) )\n",
    "print( len( country) )\n",
    "\n",
    "print(data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 16294, 7: 11588, 6: 10059, 0: 9221, 4: 8134, 5: 6950, 1: 5890, 8: 5801, 2: 5401, 9: 4638})\n"
     ]
    }
   ],
   "source": [
    "clustering_machine = sklearn.cluster.KMeans( 10 )\n",
    "clustering_results = clustering_machine.fit_predict( data )\n",
    "\n",
    "## number of responders per cluster\n",
    "print( collections.Counter( clustering_results ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have created a **ten cluster** approach.\n",
    "How do we know if it is any good?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least it seems that the number of cases in each cluster is a bit unbalanced which probably is not something that we want to have (largest cluster has 16294 cases in them and smallest 4638). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be different if we create a **five cluster** model instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 22682, 3: 18127, 2: 16068, 4: 14729, 0: 12370})\n"
     ]
    }
   ],
   "source": [
    "clustering_machine = sklearn.cluster.KMeans( 5 )\n",
    "clustering_results = clustering_machine.fit_predict( data )\n",
    "\n",
    "## number of responders per cluster\n",
    "print( collections.Counter( clustering_results ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With five clusters the balance of the clusters are a bit better and perhaps would be much easier to interpret. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the mean values per each of the identified cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t newspaper | magazines | TV news | Radio news | Internet | friends, collegues |\n",
      "Cluster 0: V217 3.0 | V218 3.0 | V219 3.0 | V220 2.0 | V223 2.0 | V224 3.0 | \n",
      "Cluster 1: V217 4.0 | V218 3.0 | V219 2.5 | V220 4.0 | V223 4.0 | V224 2.0 | \n",
      "Cluster 2: V217 3.0 | V218 3.0 | V219 3.0 | V220 2.5 | V223 3.5 | V224 4.0 | \n",
      "Cluster 3: V217 2.5 | V218 2.5 | V219 3.0 | V220 2.5 | V223 2.0 | V224 3.0 | \n",
      "Cluster 4: V217 4.0 | V218 3.0 | V219 2.0 | V220 2.0 | V223 4.0 | V224 2.0 | \n",
      "Cluster 5: V217 2.5 | V218 3.0 | V219 3.0 | V220 4.0 | V223 4.0 | V224 3.0 | \n",
      "Cluster 6: V217 3.0 | V218 3.0 | V219 3.0 | V220 4.0 | V223 2.5 | V224 3.0 | \n",
      "Cluster 7: V217 2.5 | V218 3.0 | V219 3.0 | V220 2.0 | V223 4.0 | V224 2.5 | \n",
      "Cluster 8: V217 3.0 | V218 3.0 | V219 3.0 | V220 3.5 | V223 3.0 | V224 4.0 | \n",
      "Cluster 9: V217 3.0 | V218 3.0 | V219 4.0 | V220 3.0 | V223 3.0 | V224 3.0 | \n"
     ]
    }
   ],
   "source": [
    "## clustering_results with row ID numbers\n",
    "all_clusters = set( clustering_results  )\n",
    "clustering_results_with_rows = set( enumerate( clustering_results ) )\n",
    "\n",
    "print('\\t newspaper | magazines | TV news | Radio news | Internet | friends, collegues |')\n",
    "\n",
    "for cluster in all_clusters:\n",
    "    \n",
    "    ## select entries in this cluster\n",
    "    this_cluster_rows = filter( lambda cr: cr[1] == cluster, clustering_results_with_rows )\n",
    "    this_cluster_values = []\n",
    "    \n",
    "    for entry in this_cluster_rows:\n",
    "        row = entry[0]\n",
    "        this_cluster_values.append( data[ row ] )\n",
    "        \n",
    "    print( \"Cluster\", cluster, end = ': ')\n",
    "    \n",
    "    ## compute means per cluster\n",
    "    for i, name in enumerate( selected_keys ):\n",
    "        \n",
    "        dd = set( map( lambda x: int(x[i]), this_cluster_values ) )   \n",
    "        print( name , sum( dd ) / len( dd ), end = ' | ' )\n",
    "    print()\n",
    "        \n",
    "## TODO: this is super-manual way of doing this. Pandas could do all of this for you automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "* Run the above code and explain to yourself what is done.\n",
    "* Response values -1, -2 and -3 relate to missing data (people answering I don't know etc.). Clean these values away from the dataset and redo your analysis.\n",
    "* Choose suitable variables using the codebook and your understanding and intuition.\n",
    "* Modify the number of clusters and examine how results change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking inside K-means\n",
    "\n",
    "Often we prefer to use some data-driven approaches to identify the best number of clusters. One way to achieve this is to use the [elbow_ method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)), where we visually inspect the best number of topics. Other tools exists as well, such as the [Silhouette method](https://en.wikipedia.org/wiki/Silhouette_(clustering)). Elbow is simple, but not always that clear and other methods are preferred. However, it is easy to understand.\n",
    "\n",
    "The Elbow-method measures the distance clusters' items have to the centroid (sum of squared errors, sse). It can range from 0 (all items in the clusters are at the same point as its centroid) to positive infinity (nodes are all over the place). When numer or clusters (k) is increased, it decreases SSE; but this is a balancing act: how do you balance between more clusters and additional complexity and most explainability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = {}\n",
    "\n",
    "for k in range(1, 10):\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=k).fit(data)\n",
    "    sse[k] = kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "* Draw three different k-means clusterings with centroids and related values and organize them by their SSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters 5 :  518798.13593903003\n",
      "Clusters 7 :  436435.0393688539\n",
      "Clusters 10 :  342700.2630843353\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sse = {}\n",
    "\n",
    "clusterings = {}\n",
    "n_of_clusters = [5, 7, 10]\n",
    "\n",
    "for n in n_of_clusters:\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=n).fit(data)\n",
    "    sse = kmeans.inertia_\n",
    "    print('Clusters', n, ': ', sse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the elbow method to optimize your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1115542.4939506527, 2: 811741.957204325, 3: 667096.5134278573, 4: 587774.6481817157, 5: 518821.9675530996, 6: 471760.4944610898, 7: 434649.9820351618, 8: 399826.898723904, 9: 367939.9928015232}\n"
     ]
    }
   ],
   "source": [
    "sse = {}\n",
    "\n",
    "for k in range(1, 10):\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=k).fit(data)\n",
    "    sse[k] = kmeans.inertia_\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()\n",
    "\n",
    "print(sse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would say that best number for clusters would be four or five. With five clusters we get the following clusters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t newspaper | magazines | TV news | Radio news | Internet | friends, collegues |\n",
      "Counter({1: 22258, 0: 19467, 2: 14624, 4: 13993, 3: 13634})\n",
      "Cluster 0: V217 2.5 | V218 3.0 | V219 3.0 | V220 3.0 | V223 3.5 | V224 3.0 | \n",
      "Cluster 1: V217 3.0 | V218 3.0 | V219 3.0 | V220 3.0 | V223 2.0 | V224 3.0 | \n",
      "Cluster 2: V217 3.0 | V218 3.0 | V219 3.0 | V220 4.0 | V223 3.5 | V224 3.0 | \n",
      "Cluster 3: V217 3.5 | V218 3.0 | V219 3.0 | V220 2.0 | V223 3.5 | V224 3.0 | \n",
      "Cluster 4: V217 3.0 | V218 3.0 | V219 3.0 | V220 3.0 | V223 2.5 | V224 3.0 | \n"
     ]
    }
   ],
   "source": [
    "clustering_machine = sklearn.cluster.KMeans( 5 )\n",
    "clustering_results = clustering_machine.fit_predict( data )\n",
    "\n",
    "all_clusters = set( clustering_results  )\n",
    "clustering_results_with_rows = set( enumerate( clustering_results ) )\n",
    "\n",
    "print('\\t newspaper | magazines | TV news | Radio news | Internet | friends, collegues |')\n",
    "\n",
    "print( collections.Counter( clustering_results ) )\n",
    "\n",
    "for cluster in all_clusters:\n",
    "    \n",
    "    ## select entries in this cluster\n",
    "    this_cluster_rows = filter( lambda cr: cr[1] == cluster, clustering_results_with_rows )\n",
    "    this_cluster_values = []\n",
    "    \n",
    "    for entry in this_cluster_rows:\n",
    "        row = entry[0]\n",
    "        this_cluster_values.append( data[ row ] )\n",
    "        \n",
    "    print( \"Cluster\", cluster, end = ': ')\n",
    "    \n",
    "    ## compute means per cluster\n",
    "    for i, name in enumerate( selected_keys ):\n",
    "        \n",
    "        dd = set( map( lambda x: int(x[i]), this_cluster_values ) )   \n",
    "        print( name , sum( dd ) / len( dd ), end = ' | ' )\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: daily, 2: weekly, 3: monthly, 4: less than monthly and 5: never\n",
    "\n",
    "The following attributes characterize the clusters in relation to each other: \n",
    "\n",
    "* General observation: there are no differences between the clusters in how often people get their information from magazines, tv news and friends, collegues (it is 3.0 in each cluster)\n",
    "\n",
    "* Cluster 0: Newspapers are used often as a source and internet relatively rarely\n",
    "* Cluster 1: Internet is used very often as a source of information\n",
    "* Cluster 2: Radio news and internet are rarely used source of information\n",
    "* Cluster 3: Newspapers and internet and rarely used sources but radio news are often used source for information\n",
    "* Cluster 4: The most used source of information is the internet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How these clusters correspond to nationalities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country code\n",
      "2 [('C1', [862, '0.41']), ('C4', [719, '0.34']), ('C0', [246, '0.12']), ('C2', [168, '0.08']), ('C3', [101, '0.05'])]\n",
      "41 [('C3', [1510, '0.78']), ('C2', [135, '0.07']), ('C0', [133, '0.07']), ('C4', [112, '0.06']), ('C1', [45, '0.02'])]\n",
      "52 [('C0', [523, '0.54']), ('C1', [265, '0.27']), ('C3', [98, '0.10']), ('C4', [44, '0.05']), ('C2', [40, '0.04'])]\n",
      "70 [('C2', [560, '0.28']), ('C0', [428, '0.21']), ('C3', [382, '0.19']), ('C4', [326, '0.16']), ('C1', [303, '0.15'])]\n",
      "100 [('C0', [358, '0.24']), ('C2', [304, '0.20']), ('C3', [296, '0.20']), ('C1', [284, '0.19']), ('C4', [261, '0.17'])]\n",
      "130 [('C0', [492, '0.41']), ('C1', [276, '0.23']), ('C4', [188, '0.16']), ('C2', [136, '0.11']), ('C3', [106, '0.09'])]\n",
      "135 [('C0', [470, '0.42']), ('C1', [365, '0.33']), ('C3', [126, '0.11']), ('C4', [85, '0.08']), ('C2', [71, '0.06'])]\n",
      "140 [('C4', [410, '0.28']), ('C1', [314, '0.22']), ('C2', [263, '0.18']), ('C0', [259, '0.18']), ('C3', [212, '0.15'])]\n",
      "155 [('C1', [367, '0.38']), ('C4', [215, '0.22']), ('C0', [190, '0.20']), ('C3', [129, '0.13']), ('C2', [72, '0.07'])]\n",
      "160 [('C1', [312, '0.32']), ('C0', [239, '0.24']), ('C4', [232, '0.24']), ('C3', [122, '0.12']), ('C2', [75, '0.08'])]\n",
      "165 [('C3', [316, '0.33']), ('C2', [176, '0.19']), ('C4', [174, '0.18']), ('C1', [155, '0.16']), ('C0', [126, '0.13'])]\n",
      "210 [('C1', [1123, '0.60']), ('C4', [438, '0.23']), ('C0', [195, '0.10']), ('C2', [70, '0.04']), ('C3', [60, '0.03'])]\n",
      "255 [('C1', [1137, '0.56']), ('C0', [443, '0.22']), ('C4', [308, '0.15']), ('C3', [93, '0.05']), ('C2', [50, '0.02'])]\n",
      "290 [('C1', [365, '0.39']), ('C0', [217, '0.23']), ('C4', [153, '0.16']), ('C3', [134, '0.14']), ('C2', [79, '0.08'])]\n",
      "349 [('C1', [411, '0.39']), ('C0', [350, '0.33']), ('C4', [133, '0.13']), ('C3', [107, '0.10']), ('C2', [51, '0.05'])]\n",
      "352 [('C1', [411, '0.42']), ('C0', [279, '0.28']), ('C4', [123, '0.12']), ('C3', [104, '0.11']), ('C2', [68, '0.07'])]\n",
      "360 [('C2', [348, '0.24']), ('C0', [319, '0.22']), ('C1', [318, '0.22']), ('C3', [252, '0.17']), ('C4', [237, '0.16'])]\n",
      "365 [('C0', [683, '0.29']), ('C1', [545, '0.23']), ('C4', [516, '0.22']), ('C2', [350, '0.15']), ('C3', [260, '0.11'])]\n",
      "366 [('C1', [818, '0.55']), ('C0', [346, '0.23']), ('C4', [193, '0.13']), ('C3', [132, '0.09']), ('C2', [8, '0.01'])]\n",
      "369 [('C0', [612, '0.41']), ('C1', [293, '0.20']), ('C4', [258, '0.17']), ('C2', [212, '0.14']), ('C3', [125, '0.08'])]\n",
      "370 [('C0', [555, '0.37']), ('C1', [392, '0.26']), ('C4', [341, '0.23']), ('C3', [129, '0.09']), ('C2', [74, '0.05'])]\n",
      "371 [('C2', [553, '0.51']), ('C4', [263, '0.24']), ('C0', [114, '0.10']), ('C3', [95, '0.09']), ('C1', [64, '0.06'])]\n",
      "372 [('C2', [480, '0.40']), ('C4', [476, '0.40']), ('C0', [122, '0.10']), ('C1', [86, '0.07']), ('C3', [36, '0.03'])]\n",
      "373 [('C3', [251, '0.25']), ('C0', [223, '0.22']), ('C1', [203, '0.20']), ('C2', [194, '0.19']), ('C4', [131, '0.13'])]\n",
      "380 [('C1', [821, '0.69']), ('C4', [194, '0.16']), ('C0', [150, '0.13']), ('C3', [12, '0.01']), ('C2', [8, '0.01'])]\n",
      "452 [('C3', [917, '0.59']), ('C1', [258, '0.17']), ('C0', [167, '0.11']), ('C4', [155, '0.10']), ('C2', [55, '0.04'])]\n",
      "475 [('C3', [881, '0.50']), ('C0', [367, '0.21']), ('C1', [356, '0.20']), ('C4', [87, '0.05']), ('C2', [68, '0.04'])]\n",
      "517 [('C3', [812, '0.53']), ('C1', [265, '0.17']), ('C0', [163, '0.11']), ('C2', [153, '0.10']), ('C4', [134, '0.09'])]\n",
      "552 [('C1', [432, '0.29']), ('C0', [393, '0.26']), ('C3', [364, '0.24']), ('C2', [186, '0.12']), ('C4', [124, '0.08'])]\n",
      "560 [('C0', [1394, '0.39']), ('C1', [971, '0.27']), ('C3', [763, '0.22']), ('C2', [241, '0.07']), ('C4', [162, '0.05'])]\n",
      "615 [('C1', [408, '0.35']), ('C2', [225, '0.20']), ('C4', [206, '0.18']), ('C0', [166, '0.14']), ('C3', [145, '0.13'])]\n",
      "616 [('C3', [422, '0.36']), ('C4', [272, '0.23']), ('C1', [212, '0.18']), ('C2', [152, '0.13']), ('C0', [123, '0.10'])]\n",
      "620 [('C4', [634, '0.31']), ('C3', [502, '0.25']), ('C2', [408, '0.20']), ('C1', [329, '0.16']), ('C0', [144, '0.07'])]\n",
      "640 [('C2', [431, '0.27']), ('C1', [389, '0.24']), ('C0', [348, '0.22']), ('C4', [336, '0.21']), ('C3', [85, '0.05'])]\n",
      "645 [('C2', [371, '0.31']), ('C3', [324, '0.28']), ('C4', [253, '0.21']), ('C1', [116, '0.10']), ('C0', [114, '0.10'])]\n",
      "651 [('C2', [1002, '0.66']), ('C3', [171, '0.11']), ('C0', [169, '0.11']), ('C4', [143, '0.09']), ('C1', [38, '0.02'])]\n",
      "660 [('C4', [413, '0.36']), ('C1', [283, '0.25']), ('C2', [183, '0.16']), ('C0', [175, '0.15']), ('C3', [85, '0.07'])]\n",
      "663 [('C2', [473, '0.39']), ('C4', [318, '0.27']), ('C3', [151, '0.13']), ('C0', [129, '0.11']), ('C1', [129, '0.11'])]\n",
      "667 [('C3', [291, '0.30']), ('C4', [231, '0.24']), ('C2', [190, '0.19']), ('C1', [180, '0.18']), ('C0', [89, '0.09'])]\n",
      "679 [('C2', [508, '0.59']), ('C3', [176, '0.20']), ('C4', [98, '0.11']), ('C0', [57, '0.07']), ('C1', [24, '0.03'])]\n",
      "690 [('C1', [523, '0.45']), ('C4', [407, '0.35']), ('C0', [150, '0.13']), ('C2', [70, '0.06']), ('C3', [19, '0.02'])]\n",
      "694 [('C1', [562, '0.53']), ('C4', [193, '0.18']), ('C0', [176, '0.17']), ('C2', [71, '0.07']), ('C3', [57, '0.05'])]\n",
      "703 [('C0', [624, '0.42']), ('C1', [415, '0.28']), ('C3', [181, '0.12']), ('C4', [151, '0.10']), ('C2', [107, '0.07'])]\n",
      "704 [('C0', [662, '0.44']), ('C2', [401, '0.27']), ('C3', [259, '0.17']), ('C1', [114, '0.08']), ('C4', [64, '0.04'])]\n",
      "705 [('C0', [490, '0.33']), ('C1', [388, '0.26']), ('C2', [289, '0.19']), ('C4', [203, '0.14']), ('C3', [130, '0.09'])]\n",
      "710 [('C2', [1034, '0.50']), ('C4', [411, '0.20']), ('C1', [289, '0.14']), ('C0', [220, '0.11']), ('C3', [132, '0.06'])]\n",
      "713 [('C1', [399, '0.33']), ('C4', [298, '0.25']), ('C0', [225, '0.19']), ('C2', [208, '0.17']), ('C3', [70, '0.06'])]\n",
      "732 [('C1', [468, '0.41']), ('C4', [367, '0.32']), ('C0', [140, '0.12']), ('C2', [116, '0.10']), ('C3', [56, '0.05'])]\n",
      "740 [('C0', [884, '0.37']), ('C1', [734, '0.31']), ('C4', [523, '0.22']), ('C2', [189, '0.08']), ('C3', [36, '0.02'])]\n",
      "750 [('C2', [1685, '0.41']), ('C0', [1524, '0.37']), ('C1', [379, '0.09']), ('C3', [353, '0.09']), ('C4', [137, '0.03'])]\n",
      "770 [('C2', [624, '0.56']), ('C0', [237, '0.21']), ('C3', [117, '0.10']), ('C1', [84, '0.08']), ('C4', [56, '0.05'])]\n",
      "800 [('C3', [370, '0.32']), ('C0', [292, '0.26']), ('C1', [213, '0.19']), ('C2', [171, '0.15']), ('C4', [94, '0.08'])]\n",
      "820 [('C0', [592, '0.46']), ('C1', [518, '0.40']), ('C4', [92, '0.07']), ('C2', [64, '0.05']), ('C3', [34, '0.03'])]\n",
      "830 [('C1', [994, '0.51']), ('C0', [423, '0.22']), ('C4', [388, '0.20']), ('C2', [118, '0.06']), ('C3', [42, '0.02'])]\n",
      "840 [('C3', [388, '0.33']), ('C0', [304, '0.26']), ('C2', [227, '0.19']), ('C1', [155, '0.13']), ('C4', [115, '0.10'])]\n",
      "900 [('C1', [688, '0.50']), ('C0', [302, '0.22']), ('C4', [266, '0.19']), ('C3', [82, '0.06']), ('C2', [44, '0.03'])]\n",
      "920 [('C1', [410, '0.55']), ('C0', [152, '0.21']), ('C4', [132, '0.18']), ('C3', [30, '0.04']), ('C2', [15, '0.02'])]\n"
     ]
    }
   ],
   "source": [
    "codes_and_clusters = []\n",
    "\n",
    "country_test = country[0:20]\n",
    "results_test = clustering_results[0:20]\n",
    "\n",
    "country_codes = set(country)\n",
    "country_codes = list(map(int,country_codes))\n",
    "country_codes.sort()\n",
    "\n",
    "for i in range(0, len(country)-1):\n",
    "    list_to_add = [country[i], clustering_results[i]]\n",
    "    codes_and_clusters.append(list_to_add)\n",
    "\n",
    "print('Country code')\n",
    "\n",
    "for code in country_codes:\n",
    "    cluster_dict = {'C0': 0, 'C1': 0, 'C2': 0, 'C3': 0, 'C4': 0}\n",
    "    for row in codes_and_clusters:\n",
    "        if int(row[0]) == code:\n",
    "            if row[1] == 0:\n",
    "                cluster_dict['C0'] += 1\n",
    "            elif row[1] == 1:\n",
    "                cluster_dict['C1'] += 1\n",
    "            elif row[1] == 2:\n",
    "                cluster_dict['C2'] += 1\n",
    "            elif row[1] == 3:\n",
    "                cluster_dict['C3'] += 1\n",
    "            elif row[1] == 4:\n",
    "                cluster_dict['C4'] += 1\n",
    "                \n",
    "    n_of_cases = cluster_dict['C0'] + cluster_dict['C1'] + cluster_dict['C2'] + cluster_dict['C3'] + cluster_dict['C4']\n",
    "        \n",
    "    for key in cluster_dict: \n",
    "        cluster_dict[key] = [cluster_dict[key], '{0:0.2f}'.format(cluster_dict[key] / n_of_cases)]\n",
    "\n",
    "    print(code, sorted(cluster_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that in most cases the countries have one cluster where some of the clusters is the most representative of the country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What similarities can you find between k-means and factor analysis?\n",
    "* How does k-means differ from factor analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are similar in the sense that both of them could be considered to be a tool for sinmplifying the data -- or making the data easier for a human to interpret. However, how they do it is based on different principles. What factor analysis does is that it simplifies the data by mapping the covariances and correlations between the variables. For example, if we would utilize factor analysis for the data used in this exercise, it would reduce the number of variables to smaller number of factors that describe the data. As a contrast K-means clustering groups data points into clusters and answers to the question of \"how can the observations be grouped into groups in a way that can tell us something about the structure of the data\". Factor analysis would, for example, create a factor that describes \"how media is used\". Clustering instead groups the cases in the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some reflections on K-means clustering\n",
    "\n",
    "K-means and clustering was one of the methods that were relatively easy to grasp intuitively (or at least I think so). In my own words, I would say that it just classifies data points that are close to each other as belonging to the same class, category or cluster. However, as it was with other machine learning methods, the practice of building clusters was surprisingly difficult. Finding the number of clusters that produced descriptive clusters (in the sense that \"they made sense in some way\") was surprisingly difficult. Although there is a \"mathematical formula\" for comparing different clusterings and for finding the best number of clusters (the elbow method), it does not necessarily give a unambiguous guidelines for choosing the right number of clusters. For example, in this exercise it was really difficult to decide should I have three, four or five clusters. Although, \"mathematically\" best number of clusters would have probably been four, five clusters were more descriptive, or they were easier to interpret. This \"how to choose the best number for something\" seems to be a theme that I faced many times during these exercises. \n",
    "\n",
    "My \"findings\" were that although there were differences between the clusters, the differences were quite minimal (from 2.0 to 4.0 and the \"frequency\" of using magazines, tv news and friends were the same in each cluster (now that I think of it, I am not sure if the value of 2.5 makes any sense in this context..). However, it was clear that in some cases there were differences between countries in which cluster most responders connected to that country belonged to. For example, in Haiti (country code 41) most responders belonged to the cluster C3 where radio was the main source for information. In Mexico (country code 70) the responders were distributed to the clusters quite equally. In Netherlands (code 210) most cases belonget to the cluster C1 where internet was the main source of information. \n",
    "\n",
    "I find clustering to be an interesting computational method that is probably able to provide new insights about the data (or the social world). In addition, it could be a very useful tool when analyzing textual data. In relation to the question of \"what we can do this method\" (which I seemed to ask during each of theses exercises) I would say that it is a good tool for providing descriptions/interpretations about the data in hand. Similarily to the other metohods, in the end, interpreting the clusters and what they tell us about the social world seems to be quite difficult. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
